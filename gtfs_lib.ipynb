{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GTFS:\n",
    "    def __init__(self, zip):\n",
    "        self.zip = zip\n",
    "        self.dir_split = self.zip.split('\\\\')[:-1]\n",
    "        self.root = '\\\\'.join(self.dir_split)\n",
    "        self.folder = self.zip[:-4]\n",
    "        self.output = os.path.join(self.folder, 'output')\n",
    "        self.export = os.path.join(self.output, 'final.csv')\n",
    "\n",
    "        if os.path.exists(self.folder):\n",
    "            shutil.rmtree(self.folder)\n",
    "\n",
    "        os.mkdir(self.folder)\n",
    "\n",
    "        if os.path.exists(self.output):\n",
    "            shutil.rmtree(self.output)\n",
    "            print(f\"Deleted {self.output}\")\n",
    "\n",
    "        os.mkdir(self.output)\n",
    "\n",
    "        with zipfile.ZipFile(self.zip, 'r') as myzip:\n",
    "            myzip.extractall(self.folder)\n",
    "        if os.path.exists(os.path.join(self.folder, 'agency.txt')):\n",
    "            self.agency = pd.read_csv(os.path.join(self.folder, 'agency.txt'))        \n",
    "        if os.path.exists(os.path.join(self.folder, 'calendar.txt')):\n",
    "            self.calendar = pd.read_csv(os.path.join(self.folder, 'calendar.txt'))      \n",
    "        if os.path.exists(os.path.join(self.folder, 'calendar_dates.txt')):\n",
    "            self.calendar_dates = pd.read_csv(os.path.join(self.folder, 'calendar_dates.txt'))\n",
    "        if os.path.exists(os.path.join(self.folder, 'fare_attributes.txt')):\n",
    "            self.fare_attributes = pd.read_csv(os.path.join(self.folder, 'fare_attributes.txt'))\n",
    "        if os.path.exists(os.path.join(self.folder, 'fare_rules.txt')):\n",
    "            self.fare_rules = pd.read_csv(os.path.join(self.folder, 'fare_rules.txt'))\n",
    "        if os.path.exists(os.path.join(self.folder, 'routes.txt')):\n",
    "            self.routes = pd.read_csv(os.path.join(self.folder, 'routes.txt'))\n",
    "        if os.path.exists(os.path.join(self.folder, 'shapes.txt')):\n",
    "            self.shapes = pd.read_csv(os.path.join(self.folder, 'shapes.txt'))\n",
    "        if os.path.exists(os.path.join(self.folder, 'stops.txt')):\n",
    "            self.stops = pd.read_csv(os.path.join(self.folder, 'stops.txt'))\n",
    "        if os.path.exists(os.path.join(self.folder, 'stop_times.txt')):\n",
    "            self.stop_times = pd.read_csv(os.path.join(self.folder, 'stop_times.txt'))\n",
    "        if os.path.exists(os.path.join(self.folder, 'transfers.txt')):\n",
    "            self.transfers = pd.read_csv(os.path.join(self.folder, 'transfers.txt'))\n",
    "        if os.path.exists(os.path.join(self.folder, 'trips.txt')):\n",
    "            self.trips = pd.read_csv(os.path.join(self.folder, 'trips.txt'))\n",
    "\n",
    "        shutil.rmtree(self.folder)\n",
    "\n",
    "    def max_min_rename(self, df):\n",
    "        fields_obj = {}\n",
    "\n",
    "        for column in df.columns.values.tolist():\n",
    "            if column.endswith('_x'):\n",
    "                fields_obj[column] = f'max_{column[:-2]}'\n",
    "            if column.endswith('_y'):\n",
    "                fields_obj[column] = f'min_{column[:-2]}'\n",
    "        return df.rename(columns=fields_obj)\n",
    "\n",
    "    def rename_list(self, df, list):\n",
    "        obj = {}\n",
    "        for field in list:\n",
    "            obj[field] = f'max_{field}'\n",
    "        df = df.rename(obj)\n",
    "        return df\n",
    "\n",
    "    def times_stops_trips(self):\n",
    "\n",
    "        # merge stops_times, trips, and routes\n",
    "        try:\n",
    "            # merge stop_times with trips\n",
    "            self.stop_times_trip = pd.merge(self.stop_times,self.trips, left_on='trip_id', right_on='trip_id')\n",
    "\n",
    "            # merge stop_times_trip with routes for full dataframe table\n",
    "            self.stop_times_trip_route = pd.merge(self.stop_times_trip, self.routes, left_on='route_id', right_on='route_id')\n",
    "        except:\n",
    "            print('Error merging datasets. Possibly issue with field names.')\n",
    "        \n",
    "        return self.stop_times_trip_route\n",
    "\n",
    "    def trip_stats(self):\n",
    "        self.stop_times_trip_route = self.times_stops_trips()\n",
    "\n",
    "        # group by trips and routes & find last and first stops by trip and route\n",
    "        try:\n",
    "            fields = ['trip_id', 'route_id', 'route_short_name', 'stop_id', 'stop_sequence']\n",
    "            groups = ['trip_id', 'route_id', 'route_short_name']\n",
    "            fmax = ['stop_sequence']\n",
    "            \n",
    "            # find the max stop_sequece id's and add a boolean end column\n",
    "            max_group = self.stop_times_trip_route.groupby(groups).apply(lambda s: s.loc[s.stop_sequence.idxmax(), fmax])\n",
    "\n",
    "            # find the min stop_sequece id's and add a boolean start column\n",
    "            min_group = self.stop_times_trip_route.groupby(groups).apply(lambda s: s.loc[s.stop_sequence.idxmin(), fmax])\n",
    "                    \n",
    "        except:\n",
    "            print('Issue with group by calculations')\n",
    "\n",
    "        # join min and max groups on groups list\n",
    "#         try:\n",
    "        # merge the min and max records\n",
    "        max_min_group = pd.merge(max_group, min_group, left_on=groups, right_on=groups)\n",
    "\n",
    "        max_min_group = self.max_min_rename(max_min_group)\n",
    "\n",
    "        min_ids = ['trip_id', 'route_id', 'route_short_name', 'min_stop_sequence']\n",
    "        max_ids = ['trip_id', 'route_id', 'route_short_name', 'max_stop_sequence']\n",
    "        st_trp_routes_ids = ['trip_id', 'route_id', 'route_short_name', 'stop_sequence']\n",
    "        update_fields = ['stop_id', 'arrival_time', 'departure_time']\n",
    "        drop_fields = ['pickup_type', 'drop_off_type', 'timepoint', 'shape_dist_traveled', 'trip_headsign', 'direction_id', 'wheelchair_accessible', 'route_long_name', 'route_type', 'route_color', 'route_text_color']\n",
    "        max_drop = ['service_id', 'block_id', 'shape_id']\n",
    "\n",
    "        # join min max table to stop times trips route table\n",
    "        max_stopid = pd.merge(max_min_group, self.stop_times_trip_route, left_on=max_ids, right_on=st_trp_routes_ids)\n",
    "        max_stopid = self.rename_list(max_stopid, update_fields).drop(drop_fields, axis=1).drop(max_drop, axis=1)\n",
    "\n",
    "        stats_df= pd.merge(max_stopid, self.stop_times_trip_route, left_on=min_ids, right_on=st_trp_routes_ids)\n",
    "        stats_df = self.rename_list(stats_df, update_fields).drop(drop_fields, axis=1)\n",
    "\n",
    "        stats_df = self.max_min_rename(stats_df)\n",
    "\n",
    "        return stats_df\n",
    "    \n",
    "    def route_stats(self):\n",
    "        trips = self.trip_stats()\n",
    "        trips['trips_count'] = 1\n",
    "\n",
    "        r_fields = ['route_id', 'route_short_name', 'route_long_name', 'trips_count'] \n",
    "        routes = trips[r_fields].groupby(r_fields[:-1]).count()\n",
    "\n",
    "        return routes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.7.9 64-bit",
   "display_name": "Python 3.7.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "bf28a4d67bc5641b0a9404db4ab5429a7963aeeb93183bfc676d066801f70b5b"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}